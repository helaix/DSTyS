# DSTyS Testing Rules (_testing.rules.mdc)

**Purpose:** To ensure robustness, correctness, and reliability of the DSTyS library through a comprehensive and largely automated testing strategy. Emphasizes Test-Driven Development (TDD) by porting Python DSPy tests first.
**Primary References:** DSTyS Architecture Document (`docs/planning/Architecture.md`, Section 7), EffectTS Testing Docs, Vitest Docs, `_workplan-execution.rules.mdc`.

---
**Rule ID:** `DSTYS-TEST-001`
**Rule Title:** Test-Driven Development (TDD) by Porting Python Tests
**Applies To:** All component implementation
**Purpose:** Ensure feature parity with Python DSPy and guide TypeScript implementation.
**Scope:** Development methodology.
**Guideline:**
    *   For each DSTyS component corresponding to a Python DSPy component, the TDD process is:
        1.  **Convert Python Tests:** Port the relevant Python DSPy unit/integration tests to TypeScript/Vitest. These tests should initially fail.
        2.  **Implement Component:** Write the TypeScript DSTyS component implementation to make the ported tests pass.
        3.  **Refactor:** Refactor the TypeScript code while ensuring all tests continue to pass.
    *   Workplans for component implementation (`CORE-*Implementation.md`) MUST reference their corresponding test conversion workplan (`TEST-*Tests.md`) as a prerequisite.
**Rationale:** Ensures functional equivalence with the reference implementation and drives development from specifications.

---
**Rule ID:** `DSTYS-TEST-002`
**Rule Title:** Automatable Verification Steps in Workplans
**Applies To:** Workplan definition
**Purpose:** Ensure all implemented functionality is covered by automated tests.
**Scope:** Workplan "Verification Steps" section.
**Guideline:**
    *   The 'Verification Steps' in Workplan documents for component implementation **MUST** primarily consist of "Run the converted tests from `TEST-[ComponentName]Tests.md` and ensure all pass."
    *   Any additional verification steps specific to the TypeScript implementation (e.g., type checking specific scenarios) should also be automatable via Vitest tests.
**Rationale:** Links implementation directly to test outcomes.
**Reference:** `_workplan-execution.rules.mdc` (Rule `WP-EXEC-006`)

---
**Rule ID:** `DSTYS-TEST-003`
**Rule Title:** Testing Frameworks and Tools
**Applies To:** All automated testing
**Purpose:** Standardize testing tools across the project.
**Scope:** Test implementation.
**Guideline:**
    *   **Primary Framework:** Vitest (with `@vitest/ui` for UI mode during development) is the testing framework.
    *   **EffectTS Testing:**
        *   Use `@effect/vitest` for idiomatic Effect testing (e.g., `testEffect`).
        *   Alternatively, use `Effect.runPromiseExit` or `Effect.runPromise` within standard Vitest `test` blocks and assert on the `Exit` or resolved value/error.
    *   **Mocking:**
        *   EffectTS Layers: Provide mock implementations for service dependencies (e.g., mock LMs) using `Layer.succeed(LMServiceTag, mockLMImplementation)` when testing modules that depend on them.
        *   Vitest Mocks (`vi.mock`, `vi.spyOn`): For mocking modules or specific functions not easily replaceable by EffectTS Layers, or for simpler synchronous mocks.
    *   **Assertions:** Use Vitest's built-in `expect` API.
**Rationale:** Provides a consistent and powerful testing toolkit for a TypeScript/EffectTS project.

---
**Rule ID:** `DSTYS-TEST-004`
**Rule Title:** Test Coverage Expectations
**Applies To:** All code modules
**Purpose:** Ensure critical parts of the library are well-tested.
**Scope:** Test planning and review.
**Guideline:**
    *   Aim for >85% overall test coverage for the library.
    *   Critical core primitives (`Field.ts`, `Signature.ts`, `Module.ts`, `Example.ts`, `Prediction.ts`) SHOULD aim for >90% coverage.
    *   Coverage reports (from Vitest via `v8` provider) MUST be generated and reviewed as part of CI and PRs.
**Rationale:** Provides a quantitative measure of test thoroughness.

---
**Rule ID:** `DSTYS-TEST-005`
**Rule Title:** Mocking Language Models (LMs)
**Applies To:** Tests involving `Predict` or other LM-interacting modules
**Purpose:** Isolate units under test and ensure reliable, fast, and cost-effective tests.
**Scope:** Test design for LM-dependent components.
**Guideline:**
    *   Use `dspy.utils.DummyLM` or custom mock LM implementations for most tests.
    *   Mock LMs should allow specifying expected outputs for given inputs/prompts to test module logic.
    *   If testing an EffectTS service that wraps an LM, provide a mock implementation of that service via a `Layer`.
    *   Actual calls to live LMs should be reserved for a small suite of integration/E2E tests and clearly marked/separated.
**Rationale:** Avoids flakiness and cost associated with real LM calls in unit/integration tests.

---
**Rule ID:** `DSTYS-TEST-006`
**Rule Title:** Testing EffectTS Programs Idiomatically
**Applies To:** All tests for EffectTS code
**Purpose:** Ensure effective and correct testing of EffectTS constructs.
**Scope:** Test implementation for EffectTS logic.
**Guideline:**
    *   When using `Effect.runPromiseExit` for testing:
        *   For success cases: `const exit = await Effect.runPromiseExit(myEffect); expect(Exit.isSuccess(exit)).toBe(true); if (Exit.isSuccess(exit)) { expect(exit.value).toEqual(...); }`.
        *   For failure cases: `const exit = await Effect.runPromiseExit(myEffect); expect(Exit.isFailure(exit)).toBe(true); if (Exit.isFailure(exit)) { expect(Cause.failureOption(exit.cause).pipe(Option.map((e) => e._tag)).pipe(Option.getOrNull)).toBe("MyErrorTag"); }`.
    *   Test fiber interruption and resource cleanup (`Scope`) scenarios where relevant for more complex Effect programs (less common in DSTyS core, but potentially for advanced optimizers or resource-intensive tools).
**Rationale:** Aligns testing practices with EffectTS patterns for robust error and success case validation.

---
**Rule ID:** `DSTYS-TEST-007`
**Rule Title:** Test File Structure and Naming
**Applies To:** All test files
**Purpose:** Ensure tests are organized and easy to locate.
**Scope:** `tests/` directory.
**Guideline:**
    *   Test files MUST mirror the directory structure of the `source/` directory. For example, tests for `source/primitives/Example.ts` should be in `tests/primitives/Example.test.ts`.
    *   Test files MUST end with `.test.ts`.
    *   Use descriptive names for `describe` blocks and `test` (or `it`) cases.
**Rationale:** Promotes clarity and maintainability of the test suite.

---
**Rule ID:** `DSTYS-TEST-008`
**Rule Title:** CI/CD Integration of Tests
**Applies To:** All automated tests
**Purpose:** Maintain code quality and prevent regressions automatically.
**Scope:** CI/CD pipeline configuration.
**Guideline:**
    *   All automated tests (unit, integration) MUST run in the GitHub Actions CI/CD pipeline on every PR and push to `main`/`develop`.
    *   Builds MUST fail if any tests fail.
    *   Builds MAY fail if test coverage drops below the defined threshold (e.g., 85%).
**Rationale:** Provides a safety net and ensures tests are consistently executed.